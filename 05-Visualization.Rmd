# データの要約と可視化

本章では、記述統計や可視化によってデータを要約する方法について説明する。記述統計では、統計量と呼ばれる指標を用いてデータの特徴を数値から把握する。一方で可視化においては、図表を作成することでデータの特徴を視覚的に理解することを目的とする。実証的なマーケティング研究においては、データを用いた仮説の検証という方法が主流かもしれないが、仮説検証に用いるデータはどのようなものなのかを要約し、それを（論文やレポートの）読者へ伝えるプロセスは必要である。記述統計やデータの可視化は、このプロセスにおいて機能する方法である。なお、本章の作業においても `tidyverse` を用いるので、以下のように `tidyverse` を起動してほしい。

```{r tidy, message=FALSE}
library(tidyverse)
```

## 記述統計
記述統計の利用においては、データのタイプ別に利用すべき統計量が異なることに注意が必要である。「データのタイプ」という節で確認したように、データには量的変数とカテゴリ（を示す質的）変数がある。量的変数は数値で測定できるものであり、その計算結果を解釈することも可能である。一方でカテゴリ変数は、各観測個体が属している状態やグループを表す指標であり、それを計算してもそこから含意を得るのが難しい。Rのような統計ソフトは非常に素直なので、たとえカテゴリ変数であってもそこに数値が入力されていれば、記述統計に必要な計算を実行し、結果を返してくれる。しかしながら研究においてはそれらの結果を適切に解釈する必要があり、自身が用いている変数のタイプに応じた分析を実行する必要がある。

その上で本節ではまずひとつの量的変数の情報を要約するための記述統計を紹介する。一つの数値によってデータ全体を代表させるような数値を代表値と呼ぶ。代表値はおもにデータの中心を示す指標と考えられる。本節ではデータの中心を表す指標として中央値 (median) と平均値 (mean) を紹介する。中央値は、データのすべての観測値において、その値より小さな観測値の数と大きな観測値の数が等しくなるような真ん中の値を表す。そのため、（1, 3, 2, 5, 4）というデータにおける中央値は3である。これは、このデータを、1, 2, 3, 4, 5 と並べ替えると、3よりより小さな観測値の数と大きな観測値の数が等しくなっていることから確認できる^[一方でデータの観測数（ $n$ ）が偶数である場合、$\small n/2$ 番目と、$\small (n/2)+1$ 番目が中央となるため、n個のデータの観測値を、$x_1,x_2,...,x_n$ とすると、これらふたつの値の平均値（ $\small \frac{x_{\frac{n}{2}}+x_{ \frac{n}{2}+1}}{2}$ ）が中央値となる。Rにおいては`median()` 関数によって以下のように計算することができる。]。
```{r median}
d <- c(1, 3, 2, 5, 4)
median(d)
d2 <- c(1, 3, 2, 5, 4, 6)
median(d2)

```

平均値（算術平均と呼ばれる）は、最もよく使われる代表値の一つである。平均値は、n個のデータ、$\small x_1,x_2,...,x_n$ に対して以下のように定義される。

$$\bar{x} = \frac{1}{n}\sum_i^n x_i$$

観測値と平均値の差（$x_i - \bar{x}$）は偏差と呼ばれ、偏差の和はゼロである（$\sum_ix_i - \bar{x}=0$）という性質を持つ。つまり、平均値を中心として、データの正の方向へのばらつきと負の方向へのばらつきが釣り合いが取れているということが伺える。この点が、平均値がデータの中心を表す代表値として用いられるひとつの理由である。また、平均値にはいくつかの好ましい統計的性質があるのだが、それについては後述する。Rにおいては、`mean()` 関数を用いることで分析が可能である。例えば、9人の生徒に対して行われた数学(x)と国語(y)のテスト(10 点満点)の結果が、それぞれ以下の通りであったとしよう。

- 数学: (3,3,5,5,5,5,5,7,7)
- 国語: (2,3,3,5,5,5,7,7,8)

このときの平均値は以下のように求まる。

```{r meanexam}
math <- c(3,3,5,5,5,5,5,7,7)
jpn <-  c(2,3,3,5,5,5,7,7,8)

mean(math)
mean(jpn)
```

計算の結果、どちらも平均値は5であった。データの中心を表す代表値の値が等しかったため、これら2科目のテスト結果は同じ分布を持つと判断して良いのだろうか。自明かもしれないが、そのような解釈は不適切である。具体的には、データの「ばらつき」についても確認する必要がある。分布のばらつきは、平均値からの離れ方(平均値からの偏差) によって判断される事が多く、これが大きなデータが多い場合は、よりデータは散らばっ て分布していると解釈される。一方でデータが平均の近くに集まって分布している場合、ばらつきが小さいと捉えられる。この分布のばらつきは主に、分散や標準偏差という指標で測られる。

分散 (Variance, $S^2$で定義する) は以下のように、平均からの偏差の二乗の和をデータ数で割ったものだと定義される。平均からの偏差の和を計算すると、正の方向へのズレとマイナス方向へのずれがあるので、互いに相殺しあって合計は 0 になる。そこで、偏差の二乗和を用いることでデータ全体がどの程度平均からばらついているかを把握する。
$$S^2 = \frac{1}{n}\sum_i^n (x_i-\bar{x})^2$$

しかしながら、分散は元の値を二乗しているのでもとのデータと単位が異なる。そのため、分散の正の平方根 ($\sqrt{\cdot}$) を取った値を標準偏差と呼び、この標準偏差を用いることも多い^[偏差の二乗和のかわりに偏差の絶対値を用いた平均偏差という指標も存在する。しかしながら、分散や標準偏差のほうが好ましい統計的性質を持つことから、二乗和が用いられることが多い。]。なお、Rでは `var()` と `sd()` によって分散と標準偏差をそれぞれ求める。ただし、Rの関数による計算では $s^2=\frac{1}{n-1}\sum_i^n (x_i-\bar{x})^2$ で定義される「不偏標本分散」および「不偏標準誤差」という指標を用いる。これは、これらの指標のほうが統計的に好ましい性質を持っているためであるが、Rを用いた分散の計算値が、nで割った際の手計算値と異なることがあるのでその点には注意が必要である。

```{r varsd}
var(math)
var(jpn)
```

先程の数学と国語のテスト結果データを用いて分散を計算すると、国語の方が分散が大きいことがわかる。つまり、両テストとも平均値は同じであるものの、国語のほうがそのスコアのばらつきが大きいことがわかる。このように、代表値とともにデータのばらつきに関する情報も踏まえてデータの特徴を把握することが好ましい。

観察されたデータと標準偏差を用いて、特定の観測結果がデータ内において「相対的に」どのような位置にいるのかを捉えることも可能になる。具体的には、任意の量的変数 $x_1,...,x_n$ に対して、標準化されたスコア $z_1,..,z_n$ は以下のように定義できる。

$$
z_i=\frac{(x_i-\bar{x})}{\sqrt{(S^2)}}
$$

ただし、 $S^2$ は変数 $x$ の分散である（不偏標本分散を用いることもある）。上記定義の通り、標準化スコアは観測値の平均からの偏差を標準偏差で割っており、ある観測が平均値から標準偏差何個分ズレているかを示していると解釈できる。なお、標準化スコアは、平均が0、分散が1になることも知られている。

## カテゴリ変数の要約
一方でカテゴリ変数は、代表値や分散によって含意を得るのではなく、頻度のカウント（集計）や、クロス集計を用いることが多い。これにより、各カテゴリにどれぐらいの観測数があるのかを確認することが可能になる。カテゴリ変数の内容（出現頻度）の確認には、`table()` 関数を用いる。また、`with()`関数を用いて同様の結果を得ることも可能である。ここでは、前節で保存した顧客ベースのidposデータを用いる。

```{r table, message=FALSE}
idpos_cust <- readr::read_csv("data/idpos_customer.csv")

table(idpos_cust$gender)
with(idpos_cust, table(gender))
```

また、table関数にて2つのカテゴリ変数を指定することで、両変数に対応するカテゴリの出現頻度を返してくれる。このような表のことをクロス集計表とよぶ。例えば、同データにおける各デシルランクと性別の関係は以下のように示される。

```{r}
with(idpos_cust, table(gender,decile_rank))
```

特定のカテゴリ（例、デシルランク）に着目して、カテゴリ変数（例、性別）についての集計を行うことも可能である。例えば、デシルランク10における男女差のみを調べたいときには、`filter()` 関数を用いれば良い。

```{r}
idpos_cust %>% 
  filter(decile_rank == 10) %>% 
  with(table(gender))
```


カテゴリ変数と量的変数の関係を調べることも、グループ別に量的変数の要約を行う形で可能である。また、そのための手法はすでに我々は学習済みである。具体的には、前節で利用した `group_by()` 関数を用いる。例えば、合計支出額と購買頻度の平均と標準偏差を男女ごとに確認することは、以下のような指示で可能になる。なお、tidyverseを起動していない場合には、必要に応じて `library(tidyverse)` を事前に指示してほしい。

```{r}
idpos_cust %>% 
  group_by(gender) %>% 
  summarize(mon_m = mean(monetary),
            mon_sd = sd(monetary),
            freq_m = mean(frequency),
            freq_sd = sd(frequency))
```

## データの可視化

本書でのデータの可視化では、主にtidyverse内に含まれる ggplot2 というパッケージを用いる。データは一般的に、円グラフ、折れ線グラフ、帯グラフなどの様々なグラフを用いて視覚化される。しかしなが本節では、主にヒストグラム、箱ひげ図、バイオリンプロットをRでの実行例とともに紹介する。これらの図は、量的変数の分布を視覚的に示すことについて優れた可視化の方法だと言える。ここでは、ggplot2に内包されている diamonds データを用いて可視化を学ぶ（tidyverseを起動することで自動的に ggplot2も起動されるため、このタイミングでtidyverseを起動していない場合には、必要に応じて `library(tidyverse)` によってパッケージを起動してほしい）。diamonds データについては以下のように確認できる。

```{r diamond}
head(diamonds)
```

なお、Macのデスクトップ版でggplot2等を使うと日本語が文字化けするので、Macユーザーは別途以下のコマンドを実行する必要がある。

```{r, message=FALSE}
##For mac users
theme_set(theme_gray(base_size = 10, base_family = "HiraMinProN-W3"))
```


本書の可視化では、まず、ggplot2の `ggplot()` 関数を用いて図示化のためのオブジェクトを作成する。この関数では、以下の引数を指定する。

- data: 可視化に用いるデータフレームの指定
- mapping: データから抽出する変数と画面に表示される図との関係の指定
  - mapping内で、`aes()` 関数（aesthetics）で視覚化に用いる変数とプロット要素間の接続を図ることも多い。

ggplot関数で作成された図示化オブジェクトには、着目するデータと変数が特定されている。続いて、ggplot()で作られたオブジェクトに対して、geom (geometry) 用いてグラフィックの層(layer)を加えることで図を作成する。このプロセスでは、`geom_point()` による散布図や、`geom_histogram()` によるヒストグラムなど、具体的な図表のタイプに対応する関数を利用することで、図を作成できる。また、geomに関する関数以降に `labs()` というラベルに関する関数を追加することで、図に必要な情報を加筆することが可能になる。

ggplot2を用いたデータ可視化の例として、まず本書はヒストグラムを描画する。ヒストグラムはデータの分布を離散的に示すものであり、連続変数を階級で分けて各階級の頻度を図示化する。一つの変数を扱った図なので、mapping引数ではひとつの変数を指定する。その上で作成した図示化オブジェクトに `geom_histogram()` を追加することでヒストグラムを描画する。以下では、ダイアモンドの価格の観測頻度についての可視化例である。価格の程度を離散的に区切り、その区切られた各範囲の価格を取る観測がデータ内にどれだけ存在するかを示している。


```{r histogram, message=FALSE, }
p1 <- ggplot(diamonds, mapping = aes(x = price))
p1 + geom_histogram() +
  labs(x = "価格", y = "頻度",
       title = "ヒストグラム1: ダイアモンド価格")
```

なお、縦軸を確率密度(density)に変えるときは、geom_density()を用いる。その際、fillという引数を設定すると、密度を範囲に色を塗ることができる (なお、"p1" というオブジェクトは再利用できるので、再びggplot()によって指定する必要はない)。

```{r density, message=FALSE}
p1 + geom_density(fill = "black", alpha = 0.5) +
  labs(x = "価格", y = "頻度",
       title = "ヒストグラム2: ダイアモンド価格（geom_density）")
```

箱ひげ図は、四分位数と四分位範囲等を図示化したもの。四分位数はデータを4等分する区切りの値であり、第一四分位はQ1、第二四分位はQ2、第三四分位はQ3、最大値はQ4で示される。四分位範囲はQ3-Q1の範囲で示されるものである。ここでは、Cutの質（Fair, Good, Very Good, Premium, Ideal）ごとに価格の分布を比べるため、複数の箱ひげ図を並べる例を提示する。

```{r boxplot,message=FALSE}
p2 <- ggplot(diamonds, mapping = aes(x = cut, y = price))
p2 + geom_boxplot() +
  labs(x = "Cutの質", y = "価格",
       title = "箱ひげ図1: ダイアモンド価格")

```

箱ひげ図を作成すると、ひげの上下に点が表示されることがある（上図では上部が太線のように見えている）。これは、外れ値の候補として全体の分布から離れて存在する観測値が示されている。ここで示される外れ値の候補は、Q1よりも四分位範囲$\times 1.5\times 1.5$ 以上小さい、ないしは、Q3よりも四分位範囲$\times 1.5\times 1.5$ 以上大きいかで特定される。外れ値がある場合、入力ミスなどのエラーではないか、異質な観測値でないか、を検討、確認することが必要になる。

バイオリンプロットは、箱ひげ図よりももう少し詳しくデータの分布を確認できる図である。ggplot2では、`geom_violin()` を用いる。例えば、先程の箱ひげ図をバイオリンプロットで示すと、以下のようになる。以下の図は、バイオリンプロット内に箱ひげ図を示すことでよりわかりやすい図を作成するように工夫している。

```{r ciolin,message=FALSE}
p2 + geom_violin() +
  geom_boxplot(fill = "gray", width = 0.1) +
  labs(x = "Cutの質", y = "価格",
       title = "バイオリンプロット: ダイアモンド価格")

```

バイオリンプロットで横に広がっているところは、ヒストグラムで言う山が高いところを意味しており、そこに多くのデータが集まっていることを示している。

## 二変数間の関係の要約
ここまでの内容は（カテゴリ変数に関する一部の説明を除き）、一つの変数に関する要約と可視化を扱っていた。しかし、データ分析では二つの異なる変数間の関係を捉えたいと考えることも多い。二変数間の関係を数量的に要約するための指標の代表例が共分散や相関係数である。データ数をnとする変数xとyの共分散（$S_{xy}$）は、以下のように定義される。なお、Rで共分散を求める際には `cov()` 関数を用いる。

$S_{xy}=\frac{1}{n}\sum_i^n (x_i-\bar{x})(y_i-\bar{y})$

また、$S_x$と$S_y$をそれぞれxとyの分散とし、相関係数（$\rho_{xy}$）は以下のように定義される。Rで相関係数を求める際には `cor()` 関数を用いる。

$\rho_{xy}=\frac{S_{xy}}{\sqrt{S_x^2}\cdot \sqrt{S_y^2}}$

共分散は、二つのデータ間の共変動を示す指標であるものの、この数値を持って我々研究者が二変数の関係について（例えばその強弱などを）解釈するのは困難である。そこで、二変数間の関係を数値的に解釈する場合には、一般的に相関係数を用いる。相関係数は、-1 から 1 までの値を取り、正の値を取る場合は正の相関、負の値を取る場合は負の相関を、着目している二つの変数が持つことが知られている。また、相関係数が正（負）の値かつ1に近いほど強い正（負）の相関であることが知られている。ただし、相関係数で表される二変数間の関係は、線形関係の程度である。言い換えると、相関が高いとはデータがどれだけ直線上に集まって分布しているかを示しており、グラフ等で示される線形関係の傾きについては何も回答することができないという点に注意が必要である。
例えば、以下のようなデータセットを考える。

```{r datasetup}
X <- tibble(x1 = c(-3, -1, 0, 2, 5), y1 = c(16, 12, 10, 6, 0), y2 = c(8, 6, 5, 3, 0))
X
```

このデータセットにおける x1 と y1 の相関係数は -1 であり、両者の関係を図で示すと、すべてのデータが直線上（$y=-2x+10$）に並ぶことがわかる。一方で、x1 と y2 との相関係数も -1 であるものの、両者の線形関係は $y=-x+5$である。このことからも、相関係数が線形関数の傾きや切片についての情報は何も持たないことがわかる。

```{r, message=FALSE}
cor(X$x1, X$y1)

ggplot(data = X, mapping = aes(x = x1, y = y1)) + 
  geom_point() +
  geom_smooth(method = lm)
```

また我々は、二変数間の相関係数がゼロであることが、両者が無関係であることを意味しないことにも注意をしなければならない。例えば、以下のようなデータセットにおけるA と B の相関は 0 になる。

```{r, echo=FALSE}
AB <- tibble(A = c(-2, -1, 0, 1, 2), B = c(4, 1, 0, 1, 4))
AB
```

```{r}
cor(AB$A, AB$B)
```
しかしながら、両者の関係を描画すると、$y = x^2$ という二次関数の関係にあることがわかる。つまり、相関係数がゼロだからといって、二つの変数間に関係がないと結論づける事はできず、相関ではなく異なる複数の分析アプローチによって関係を特定していくことが必要になる。

```{r}
ggplot(data = AB, mapping = aes(x = A, y = B)) + 
  geom_point() + 
  geom_smooth(method = lm, formula = y ~ x + I(x^2), se = FALSE)
```

勘の良い読者であればすでに気づいているかも知れないが、二変数間の関係についての可視化もggplot2にて対応できる。具体的には、`geom_point()`という関数を用いるのだが、それだけではなく、mappingに対する引数として、x と y 二つの変数を指定することが必要になる。ダイアモンドの価格は、カラット数に大きく依存すると考えられる。そこで、以下のようにカラット数と価格との間の共分散と相関を計算する。

```{r diamondcov}
cov(diamonds$carat,diamonds$price)
cor(diamonds$carat,diamonds$price)
```

これらの変数間の相関係数は約0.92であり、高い正の相関関係であることが確認された。続いて、これらの変数の関係を可視化する。二変数間の関係を端的に可視化する方法が散布図である。散布図は、一方の変数を横軸に、もう一方の変数を縦軸に取り、各データのそれぞれの値の組み合わせをプロットしたものである。

```{r plotnormal, message=FALSE}
p3 <- ggplot(diamonds, mapping = aes(x = carat, y = price))
p3 + geom_point() +
  labs(x = "カラット", y = "価格",
       title = "散布図1: カラット：価格")

```

研究目的次第では、二つの変数間の関係をカテゴリごとに比較したい場合もあるだろう。例えば、我々はカラットと価格の関係は、カットの質によって変わるのか、という問いに関心があるとしよう。その場合には、(1) 同一図内にてカテゴリごとに色分けする方法と、(2) カテゴリごとに分割して図示化する方法がある。それぞれのggplot2での実行方法は、以下のとおりである。

1. Mapping = aes() 内に、 color = categ_varと指定することで、categ_var変数のカテゴリに基づき色分けする。
2. facet_grid() や facet_wrap() を用いる。

まず、(1) の図内での色分け方法は、以下のようなコマンドで実行できる。

```{r plotcolor, message = FALSE}
p4 <- ggplot(diamonds, mapping = aes(x = carat, y = price, color = cut))
p4 + geom_point() +
  labs(x = "カラット", y = "価格", color = "カット",
       title = "散布図 2: カット別、カラット：価格")

```

このように、`mapping = aes()` 内にて色付けに関する引数を設定することで散布図内の観測値を色分けできる。ただし、ここで重要なのは、`color = `という引数では、カテゴリ変数を指定すべきであり、色そのもの（例えば、redやblue）を指定するものではないということである。しかしながら、散布図 2のように多くのカテゴリが含まれる場合には、この可視化の方法だと逆に見にくいかもしれない。そこで、以下の方法を紹介する。`facet_wrap()` を用いた図の作成では、散布図 2のように color 引数を指定する必要はなく、p3 を再利用できる。`geom_point()` で散布図作成の指示を与えたあとに、`facet_wrap()` のレイヤーを重ねる指示を与えれば、散布図 3が作成される。

```{r plotfacet, message = FALSE}
p3 + geom_point() + facet_wrap(~cut) +
  labs(x = "カラット", y = "価格",
       title = "散布図 3: カット別、カラット：価格")

```

散布図 3をみると、基本的にはカラット数と価格には正の相関があるものの、カットの質が低い（例、Fair）場合にはばらつきが大きいことがうかがえる。

これまでに学んだdplyrによるデータ処理方法をパイプ演算子でつなげることで、特定の群のみを対象にした図示化も容易になる。ここでは例として、1.00カラット以上と未満とで分けて、それぞれのヒストグラムを作成してみる。

```{r pipegg, message=FALSE}
p5 <- diamonds %>% 
  filter(carat >= 1.0) %>% 
  ggplot(mapping = aes(x = price))
p5 + geom_histogram() +
  labs(x = "価格", y = "頻度",
       title = "ヒストグラム:1.00カラット以上")
p6 <- diamonds %>% 
  filter(carat < 1.0) %>% 
  ggplot(mapping = aes(x = price))
p6 + geom_histogram() +
  labs(x = "価格", y = "頻度",
       title = "ヒストグラム:1.00カラット未満")

```

Rで図を作成したら保存（出力）したいと考えることも多いだろう。日本語を使っていない図はggsaveを使い簡単に保存できる。具体的には、まず、作成した図そのもの（図示化のためのggplot() オブジェクトではない）をオブジェクトとして定義（例、plot1）する。ggsaveの使用例は以下の様になる (以下は見本コード)。

```{r eval=FALSE}
ggsave(filename = "plot1.pdf", 
 plot = plot1, width = 10, height = 5, units = "cm")
```

日本語を含む頭の場合、`quartz()` を用いた以下の手順を経て図を保存する。
1. quartz()で作図デバイスを起動する。
2. 作図デバイスを開いたまま、Rstudio内で図を表示する。
3. dev.off()という指示で作図デバイスを閉じることで図が保存される。


また、Rstudio内のplotタブから、クリック-バイ-クリックで実行することも可能である（Export -> Save as Image/ Save as PDF -> Directory -> File name）。

## 参考文献
倉田博史・星野崇宏（2011）「入門統計解析」、新世社.

Healy, Kieran (2018) *Data Visualization: A Practical Introduction*, Princeton University Press.
